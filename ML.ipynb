{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Sex          Region DST_R Localization hiv_def hiv Cot Alcohol.abuse  \\\n",
      "0    Male          Odessa     1            1       0   0   0             0   \n",
      "1    Male          Odessa     1            1       0   0   0             0   \n",
      "2  Female         Poltava     2            1       0   0   0             0   \n",
      "3  Female         Poltava     2            1       0   0   0             0   \n",
      "4  Female  Dnipropetrovsk     1            1       0   0   0             0   \n",
      "\n",
      "  Injecting.drug.user Homeless  ... DST_Am DST_Cm DST_LFX DST_MFX DST_PAS  \\\n",
      "0                   0        0  ...      0      2       0       0       2   \n",
      "1                   0        0  ...      0      2       0       0       2   \n",
      "2                   0        0  ...      0      0       0       0       0   \n",
      "3                   0        0  ...      0      0       0       0       0   \n",
      "4                   0        0  ...      0      0       0       0       2   \n",
      "\n",
      "  DST_Km DST_Ofx DST_Et DST_Lzd DST_Cs  \n",
      "0      2       2      0       0      0  \n",
      "1      2       2      0       0      0  \n",
      "2      0       0      0       0      0  \n",
      "3      0       0      0       0      0  \n",
      "4      2       2      1       0      2  \n",
      "\n",
      "[5 rows x 32 columns]\n",
      "   imputed_weight  elapsed_time  Age\n",
      "0            72.0           9.0   35\n",
      "1            52.5         609.0   35\n",
      "2            69.0         179.0   49\n",
      "3            70.0         179.0   50\n",
      "4            66.0           0.0   45\n",
      "dropout\n",
      "0    139148\n",
      "1     11364\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"clean_ukr.csv\")\n",
    "\n",
    "if 'X' in data.columns:\n",
    "    data = data.drop(columns=['X'])\n",
    "\n",
    "# Create new variables based on conditions\n",
    "data['hiv'] = data['takes_art'].notna().astype(int)\n",
    "data['Cot'] = data['Cotrimoxazole.treatment'].notna().astype(int)\n",
    "data['new_prev'] = data['new_prev'].fillna('New')\n",
    "data['prev_treatment'] = (data['new_prev'] == 'Previously treated').astype(int)\n",
    "\n",
    "# Convert columns to appropriate types\n",
    "categorical_cols = [\n",
    "    'Sex', 'Region', 'DST_R', 'Localization', 'hiv_def', \n",
    "    'hiv', 'Cot', 'Alcohol.abuse', 'Injecting.drug.user', 'Homeless', \n",
    "    'Unemployed', 'healthcare_worker', 'Prisoner', 'migrant_refugee', \n",
    "    'prev_treatment', 'Bactec', 'LJ', 'GeneXpert', 'DST_E', 'DST_Z', 'DST_S', \n",
    "    'DST_H', 'DST_Am', 'DST_Cm', 'DST_LFX', 'DST_MFX', 'DST_PAS', 'DST_Km', \n",
    "    'DST_Ofx', 'DST_Et', 'DST_Lzd', 'DST_Cs'\n",
    "]\n",
    "numerical_cols = ['imputed_weight', 'elapsed_time', 'Age']\n",
    "\n",
    "# Convert categorical variables to category type\n",
    "for col in categorical_cols:\n",
    "    data[col] = data[col].astype('category')\n",
    "\n",
    "# Convert numerical columns to numeric type\n",
    "for col in numerical_cols:\n",
    "    data[col] = pd.to_numeric(data[col], errors='coerce')\n",
    "\n",
    "# Set the response variable\n",
    "data['dropout'] = (data['final_outcome_group'] == 'Treatment discontinuation').astype(int)\n",
    "\n",
    "# Check the transformation\n",
    "print(data[categorical_cols].head())\n",
    "print(data[numerical_cols].head())\n",
    "print(data['dropout'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Cure or Treatment Completion' 'Treatment discontinuation'\n",
      " 'Death or Palliative Care' 'Treatment in process' 'Failure']\n"
     ]
    }
   ],
   "source": [
    "data = data[data['final_outcome_group'] != \"Transfer\"]\n",
    "\n",
    "print(data['final_outcome_group'].unique())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CART Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9162820255535488\n",
      "Confusion Matrix:\n",
      " [[27293   318]\n",
      " [ 2185   102]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96     27611\n",
      "           1       0.24      0.04      0.08      2287\n",
      "\n",
      "    accuracy                           0.92     29898\n",
      "   macro avg       0.58      0.52      0.52     29898\n",
      "weighted avg       0.87      0.92      0.89     29898\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define features and target variable\n",
    "X = data[categorical_cols + numerical_cols]\n",
    "y = data['dropout']\n",
    "\n",
    "# Convert categorical variables to dummy/indicator variables\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "\n",
    "# Initialize and train the decision tree classifier\n",
    "clf = DecisionTreeClassifier(random_state=123)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict the response for test dataset\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(f\"Accuracy: {metrics.accuracy_score(y_test, y_pred)}\")\n",
    "print(f\"Confusion Matrix:\\n {metrics.confusion_matrix(y_test, y_pred)}\")\n",
    "print(f\"Classification Report:\\n {metrics.classification_report(y_test, y_pred)}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearchCV Parameter Tuning for Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 10, 'min_samples_split': 2}\n",
      "Best Score: 0.9241491763525378\n",
      "Accuracy: 0.923506589069503\n",
      "Confusion Matrix:\n",
      " [[27611     0]\n",
      " [ 2287     0]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     27611\n",
      "           1       0.00      0.00      0.00      2287\n",
      "\n",
      "    accuracy                           0.92     29898\n",
      "   macro avg       0.46      0.50      0.48     29898\n",
      "weighted avg       0.85      0.92      0.89     29898\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/pkg.8/academic-ml/spring-2024/install/spring-2024-pyt/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/share/pkg.8/academic-ml/spring-2024/install/spring-2024-pyt/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/share/pkg.8/academic-ml/spring-2024/install/spring-2024-pyt/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 10, 20, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 5, 10],\n",
    "    'max_features': [None, 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "# Initialize the Decision Tree model\n",
    "clf = DecisionTreeClassifier(random_state=123)\n",
    "\n",
    "# Set up GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=clf, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit the model\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and best score\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best Score: {grid_search.best_score_}\")\n",
    "\n",
    "# Predict using the best model\n",
    "best_clf = grid_search.best_estimator_\n",
    "y_pred = best_clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(f\"Accuracy: {metrics.accuracy_score(y_test, y_pred)}\")\n",
    "print(f\"Confusion Matrix:\\n {metrics.confusion_matrix(y_test, y_pred)}\")\n",
    "print(f\"Classification Report:\\n {metrics.classification_report(y_test, y_pred)}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HistGradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/9198291.1.p100/ipykernel_1006896/4100158848.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[col] = X[col].cat.codes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9245100006689411\n",
      "Confusion Matrix:\n",
      " [[27510   101]\n",
      " [ 2156   131]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96     27611\n",
      "           1       0.56      0.06      0.10      2287\n",
      "\n",
      "    accuracy                           0.92     29898\n",
      "   macro avg       0.75      0.53      0.53     29898\n",
      "weighted avg       0.90      0.92      0.90     29898\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "# Define features and target variable\n",
    "X = data[categorical_cols + numerical_cols]\n",
    "y = data['dropout']\n",
    "\n",
    "# Convert categorical variables to category codes, preserving the natural categorical nature\n",
    "for col in categorical_cols:\n",
    "    X[col] = X[col].cat.codes\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "\n",
    "# Initialize and train the HistGradientBoostingClassifier\n",
    "hist_clf = HistGradientBoostingClassifier(random_state=123)\n",
    "\n",
    "# Fit the model\n",
    "hist_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict the response for the test dataset\n",
    "y_pred = hist_clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(f\"Accuracy: {metrics.accuracy_score(y_test, y_pred)}\")\n",
    "print(f\"Confusion Matrix:\\n {metrics.confusion_matrix(y_test, y_pred)}\")\n",
    "print(f\"Classification Report:\\n {metrics.classification_report(y_test, y_pred)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearchCV Parameter Tuning for HistGradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'learning_rate': 0.1, 'max_iter': 200, 'max_leaf_nodes': 20, 'min_samples_leaf': 30}\n",
      "Best Score: 0.9251358809264989\n",
      "Accuracy: 0.9251454946819185\n",
      "Confusion Matrix:\n",
      " [[27544    67]\n",
      " [ 2171   116]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96     27611\n",
      "           1       0.63      0.05      0.09      2287\n",
      "\n",
      "    accuracy                           0.93     29898\n",
      "   macro avg       0.78      0.52      0.53     29898\n",
      "weighted avg       0.90      0.93      0.89     29898\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_iter': [100, 200, 300],\n",
    "    'max_leaf_nodes': [10, 20, 50], # From 30\n",
    "    'min_samples_leaf': [1, 5, 30] # From 10\n",
    "}\n",
    "\n",
    "# Set up GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=HistGradientBoostingClassifier(random_state=123),\n",
    "                           param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# Fit the model\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and best score\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best Score: {grid_search.best_score_}\")\n",
    "\n",
    "# Predict using the best model\n",
    "best_hist_clf = grid_search.best_estimator_\n",
    "y_pred = best_hist_clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(f\"Accuracy: {metrics.accuracy_score(y_test, y_pred)}\")\n",
    "print(f\"Confusion Matrix:\\n {metrics.confusion_matrix(y_test, y_pred)}\")\n",
    "print(f\"Classification Report:\\n {metrics.classification_report(y_test, y_pred)}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important Features from LASSO on Both Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols2 = [\n",
    "    'Sex', 'Region', 'DST_R', 'Localization', 'hiv_def', 'hiv', 'Cot', \n",
    "    'Alcohol.abuse', 'Injecting.drug.user', 'Homeless', 'Unemployed', \n",
    "    'healthcare_worker', 'Prisoner', 'migrant_refugee', 'prev_treatment', \n",
    "    'Bactec', 'LJ', 'GeneXpert', 'DST_E', 'DST_Z', 'DST_S', 'DST_H', \n",
    "    'DST_Am', 'DST_Cm', 'DST_LFX', 'DST_MFX', 'DST_PAS', 'DST_Km', \n",
    "    'DST_Ofx', 'DST_Et', 'DST_Lzd', 'DST_Cs'\n",
    "]\n",
    "\n",
    "numerical_cols2 = ['imputed_weight', 'Age']\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CART LASSO Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.923506589069503\n",
      "Confusion Matrix:\n",
      " [[27611     0]\n",
      " [ 2287     0]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     27611\n",
      "           1       0.00      0.00      0.00      2287\n",
      "\n",
      "    accuracy                           0.92     29898\n",
      "   macro avg       0.46      0.50      0.48     29898\n",
      "weighted avg       0.85      0.92      0.89     29898\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/pkg.8/academic-ml/spring-2024/install/spring-2024-pyt/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/share/pkg.8/academic-ml/spring-2024/install/spring-2024-pyt/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/share/pkg.8/academic-ml/spring-2024/install/spring-2024-pyt/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Define features and target variable\n",
    "X = data[categorical_cols2 + numerical_cols]\n",
    "y = data['dropout']\n",
    "\n",
    "# Convert categorical variables to dummy/indicator variables\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "\n",
    "# Initialize the Decision Tree Classifier with the best parameters\n",
    "clf = DecisionTreeClassifier(\n",
    "    max_depth=None, \n",
    "    max_features='sqrt', \n",
    "    min_samples_leaf=10, \n",
    "    min_samples_split=2, \n",
    "    random_state=123\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict the response for the test dataset\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(f\"Accuracy: {metrics.accuracy_score(y_test, y_pred)}\")\n",
    "print(f\"Confusion Matrix:\\n {metrics.confusion_matrix(y_test, y_pred)}\")\n",
    "print(f\"Classification Report:\\n {metrics.classification_report(y_test, y_pred)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HistGradientBoostingClassifier LASSO Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9234731420161884\n",
      "Confusion Matrix:\n",
      " [[27609     2]\n",
      " [ 2286     1]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     27611\n",
      "           1       0.33      0.00      0.00      2287\n",
      "\n",
      "    accuracy                           0.92     29898\n",
      "   macro avg       0.63      0.50      0.48     29898\n",
      "weighted avg       0.88      0.92      0.89     29898\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "# Define features and target variable\n",
    "X = data[categorical_cols2 + numerical_cols2]\n",
    "y = data['dropout']\n",
    "\n",
    "# Convert categorical variables to dummy/indicator variables\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "\n",
    "# Initialize the HistGradientBoostingClassifier with the best parameters\n",
    "clf = HistGradientBoostingClassifier(\n",
    "    learning_rate=0.1, \n",
    "    max_iter=200, \n",
    "    max_leaf_nodes=20, \n",
    "    min_samples_leaf=30,\n",
    "    random_state=123\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict the response for the test dataset\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(f\"Accuracy: {metrics.accuracy_score(y_test, y_pred)}\")\n",
    "print(f\"Confusion Matrix:\\n {metrics.confusion_matrix(y_test, y_pred)}\")\n",
    "print(f\"Classification Report:\\n {metrics.classification_report(y_test, y_pred)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
